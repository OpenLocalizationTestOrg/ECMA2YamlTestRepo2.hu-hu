### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.RecognizedAudio
  id: RecognizedAudio
  children:
  - System.Speech.Recognition.RecognizedAudio.AudioPosition
  - System.Speech.Recognition.RecognizedAudio.Duration
  - System.Speech.Recognition.RecognizedAudio.Format
  - System.Speech.Recognition.RecognizedAudio.GetRange(System.TimeSpan,System.TimeSpan)
  - System.Speech.Recognition.RecognizedAudio.StartTime
  - System.Speech.Recognition.RecognizedAudio.WriteToAudioStream(System.IO.Stream)
  - System.Speech.Recognition.RecognizedAudio.WriteToWaveStream(System.IO.Stream)
  langs:
  - csharp
  name: RecognizedAudio
  nameWithType: RecognizedAudio
  fullName: System.Speech.Recognition.RecognizedAudio
  type: Class
  summary: "Adjon meg, amely pedig a hang társított egy <xref href=&quot;System.Speech.Recognition.RecognitionResult&quot;> </xref>."
  remarks: "A beszédfelismerési hoz létre a felismerési művelet részeként a hangbemenetet kapcsolatos információkat. A felismert hang eléréséhez használja a <xref:System.Speech.Recognition.RecognitionResult.Audio%2A>tulajdonságot vagy a <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A>metódus a <xref:System.Speech.Recognition.RecognitionResult>.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> </xref:System.Speech.Recognition.RecognitionResult.Audio%2A>       A felismerési eredmények állíthat elő a következő események és módszerek a <xref:System.Speech.Recognition.SpeechRecognizer>és <xref:System.Speech.Recognition.SpeechRecognitionEngine>osztályok:-események:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized?displayProperty=fullName>és <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized?displayProperty=fullName>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected?displayProperty=fullName>és <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected?displayProperty=fullName>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=fullName>és <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=fullName>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted?displayProperty=fullName>és <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted?displayProperty=fullName>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=fullName>-módszerek:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A?displayProperty=fullName>és <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A?displayProperty=fullName>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A?displayProperty=fullName>és <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A?displayProperty=fullName>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A?displayProperty=fullName>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=fullName>> [!IMPORTANT] > A felismerési emulált Beszédfelismerés által visszaadott eredmény nem tartalmaz felismert hang.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.SpeechRecognizer> Ilyen felismerési eredmény a <xref:System.Speech.Recognition.RecognitionResult.Audio%2A>tulajdonság beolvasása `null` és annak <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A>metódus kivételt jelez.</xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> </xref:System.Speech.Recognition.RecognitionResult.Audio%2A> A beszédfelismerés emulált kapcsolatos további információkért tekintse meg a `EmulateRecognize` és `EmulateRecognizeAsync` módszerek a <xref:System.Speech.Recognition.SpeechRecognizer>és <xref:System.Speech.Recognition.SpeechRecognitionEngine>osztályok.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.SpeechRecognizer>"
  example:
  - "The following example handles the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=fullName>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=fullName>, or <xref:System.Speech.Recognition.Grammar.SpeechRecognized?displayProperty=fullName> event and outputs to the console information about the recognized audio that is associated with the recognition result.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  RecognitionResult result = e.Result;  \n  \n  Console.WriteLine(\"Grammar({0}): {1}\",  \n    result.Grammar.Name, result.Text);  \n  \n  if (e.Result.Audio != null)  \n  {  \n    RecognizedAudio audio = e.Result.Audio;  \n  \n    Console.WriteLine(\"   start time: {0}\", audio.StartTime);  \n    Console.WriteLine(\"   encoding format: {0}\", audio.Format.EncodingFormat);  \n    Console.WriteLine(\"   position: {0}, duration: {1}\",  \n      audio.AudioPosition, audio.Duration);  \n  }  \n  \n  // Add event handler code here.  \n}  \n```"
  syntax:
    content: public class RecognizedAudio
  inheritance:
  - System.Object
  implements: []
  inheritedMembers: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognizedAudio.AudioPosition
  id: AudioPosition
  parent: System.Speech.Recognition.RecognizedAudio
  langs:
  - csharp
  name: AudioPosition
  nameWithType: RecognizedAudio.AudioPosition
  fullName: System.Speech.Recognition.RecognizedAudio.AudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Lekérdezi a bemeneti hangadatfolyam helyét a felismert hang elejéhez."
  remarks: "Ez a tulajdonság helyezi a elején a felismert kifejezést a beviteli eszköz létrehozott hangadatfolyam hivatkozik. Ezzel szemben a `RecognizerAudioPosition` tulajdonsága a <xref:System.Speech.Recognition.SpeechRecognitionEngine>és <xref:System.Speech.Recognition.SpeechRecognizer>osztályok hivatkozzon a felismerő pozíció belül a hangbemenetet.</xref:System.Speech.Recognition.SpeechRecognizer> </xref:System.Speech.Recognition.SpeechRecognitionEngine> Ezek a pozíciók eltérő lehet. További információkért lásd: [használatával Beszéd felismerés események](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482).       A <xref:System.Speech.Recognition.RecognizedAudio.StartTime%2A>tulajdonság lekérdezi a rendszer pontos ideje a felismerési művelet elején.</xref:System.Speech.Recognition.RecognizedAudio.StartTime%2A>"
  example:
  - "The following example handles the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=fullName> or <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=fullName> event and outputs to the console information about the recognized audio that is associated with the recognition result.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  RecognitionResult result = e.Result;  \n  \n  Console.WriteLine(\"Grammar({0}): {1}\",  \n    result.Grammar.Name, result.Text);  \n  \n  if (e.Result.Audio != null)  \n  {  \n    RecognizedAudio audio = e.Result.Audio;  \n  \n    Console.WriteLine(\"   start time: {0}\", audio.StartTime);  \n    Console.WriteLine(\"   encoding format: {0}\", audio.Format.EncodingFormat);  \n    Console.WriteLine(\"   position: {0}, duration: {1}\",  \n      audio.AudioPosition, audio.Duration);  \n  }  \n  \n  // Add event handler code here.  \n}  \n```"
  syntax:
    content: public TimeSpan AudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "A bemeneti hangadatfolyam elején a helyét a felismert hang."
  overload: System.Speech.Recognition.RecognizedAudio.AudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognizedAudio.Duration
  id: Duration
  parent: System.Speech.Recognition.RecognizedAudio
  langs:
  - csharp
  name: Duration
  nameWithType: RecognizedAudio.Duration
  fullName: System.Speech.Recognition.RecognizedAudio.Duration
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Lekérdezi a bemeneti hangadatfolyam a felismert Audio időtartama."
  remarks: ''
  example:
  - "The following example handles the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=fullName> or <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=fullName> event and outputs to the console information about the recognized audio that is associated with the recognition result.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  RecognitionResult result = e.Result;  \n  \n  Console.WriteLine(\"Grammar({0}): {1}\",  \n    result.Grammar.Name, result.Text);  \n  \n  if (e.Result.Audio != null)  \n  {  \n    RecognizedAudio audio = e.Result.Audio;  \n  \n    Console.WriteLine(\"   start time: {0}\", audio.StartTime);  \n    Console.WriteLine(\"   encoding format: {0}\", audio.Format.EncodingFormat);  \n    Console.WriteLine(\"   position: {0}, duration: {1}\",  \n      audio.AudioPosition, audio.Duration);  \n  }  \n  \n  // Add event handler code here.  \n}  \n```"
  syntax:
    content: public TimeSpan Duration { get; }
    return:
      type: System.TimeSpan
      description: "A felismert hang belül a bemeneti hangadatfolyam időtartama."
  overload: System.Speech.Recognition.RecognizedAudio.Duration*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognizedAudio.Format
  id: Format
  parent: System.Speech.Recognition.RecognizedAudio
  langs:
  - csharp
  name: Format
  nameWithType: RecognizedAudio.Format
  fullName: System.Speech.Recognition.RecognizedAudio.Format
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Lekérdezi a hang, a motor által feldolgozott formátuma."
  remarks: ''
  example:
  - "The following example handles the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=fullName> or <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=fullName> event and outputs to the console information about the recognized audio that is associated with the recognition result.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  RecognitionResult result = e.Result;  \n  \n  Console.WriteLine(\"Grammar({0}): {1}\",  \n    result.Grammar.Name, result.Text);  \n  \n  if (e.Result.Audio != null)  \n  {  \n    RecognizedAudio audio = e.Result.Audio;  \n  \n    Console.WriteLine(\"   start time: {0}\", audio.StartTime);  \n    Console.WriteLine(\"   encoding format: {0}\", audio.Format.EncodingFormat);  \n    Console.WriteLine(\"   position: {0}, duration: {1}\",  \n      audio.AudioPosition, audio.Duration);  \n  }  \n  \n  // Add event handler code here.  \n}  \n```"
  syntax:
    content: public System.Speech.AudioFormat.SpeechAudioFormatInfo Format { get; }
    return:
      type: System.Speech.AudioFormat.SpeechAudioFormatInfo
      description: "A hang dolgozza fel a beszédfelismerés nyelvével formátuma."
  overload: System.Speech.Recognition.RecognizedAudio.Format*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognizedAudio.GetRange(System.TimeSpan,System.TimeSpan)
  id: GetRange(System.TimeSpan,System.TimeSpan)
  parent: System.Speech.Recognition.RecognizedAudio
  langs:
  - csharp
  name: GetRange(TimeSpan,TimeSpan)
  nameWithType: RecognizedAudio.GetRange(TimeSpan,TimeSpan)
  fullName: System.Speech.Recognition.RecognizedAudio.GetRange(TimeSpan,TimeSpan)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Kiválasztja, és ismeri az aktuális szakasz hang bináris adatként adja vissza."
  remarks: ''
  example:
  - "The following example creates a speech recognition grammar for name input, adds a handler for the <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event, and loads the grammar into an in-process speech recognizer. Then it writes the audio information for the name portion of the input to an audio file. The audio file is used as input to a <xref:System.Speech.Synthesis.SpeechSynthesizer> object, which speaks a phrase that includes the recorded audio.  \n  \n```  \nprivate static void AddNameGrammar(SpeechRecognitionEngine recognizer)  \n{  \n  GrammarBuilder builder = new GrammarBuilder();  \n  builder.Append(\"My name is\");  \n  builder.AppendWildcard();  \n  \n  Grammar nameGrammar = new Grammar(builder);  \n  nameGrammar.Name = \"Name Grammar\";  \n  nameGrammar.SpeechRecognized +=  \n    new EventHandler<SpeechRecognizedEventArgs>(  \n      NameSpeechRecognized);  \n  \n  recognizer.LoadGrammar(nameGrammar);  \n}  \n  \n// Handle the SpeechRecognized event of the name grammar.  \nprivate static void NameSpeechRecognized(  \n  object sender, SpeechRecognizedEventArgs e)  \n{  \n  Console.WriteLine(\"Grammar ({0}) recognized speech: {1}\",  \n    e.Result.Grammar.Name, e.Result.Text);  \n  \n  try  \n  {  \n  \n    // The name phrase starts after the first three words.  \n    if (e.Result.Words.Count < 4)  \n    {  \n  \n      // Add code to check for an alternate that contains the wildcard.  \n      return;  \n    }  \n  \n    RecognizedAudio audio = e.Result.Audio;  \n    TimeSpan start = e.Result.Words[3].AudioPosition;  \n    TimeSpan duration = audio.Duration - start;  \n  \n    // Add code to verify and persist the audio.  \n    string path = @\"C:\\temp\\nameAudio.wav\";  \n    using (Stream outputStream = new FileStream(path, FileMode.Create))  \n    {  \n      RecognizedAudio nameAudio = audio.GetRange(start, duration);  \n      nameAudio.WriteToWaveStream(outputStream);  \n      outputStream.Close();  \n    }  \n  \n    Thread testThread =  \n      new Thread(new ParameterizedThreadStart(TestAudio));  \n    testThread.Start(path);  \n  }  \n  catch (Exception ex)  \n  {  \n    Console.WriteLine(\"Exception thrown while processing audio:\");  \n    Console.WriteLine(ex.ToString());  \n  }  \n}  \n  \n// Use the speech synthesizer to play back the .wav file  \n// that was created in the SpeechRecognized event handler.  \n  \nprivate static void TestAudio(object item)  \n{  \n  string path = item as string;  \n  if (path != null && File.Exists(path))  \n  {  \n    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  \n    PromptBuilder builder = new PromptBuilder();  \n    builder.AppendText(\"Hello\");  \n    builder.AppendAudio(path);  \n    synthesizer.Speak(builder);  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizedAudio GetRange (TimeSpan audioPosition, TimeSpan duration);
    parameters:
    - id: audioPosition
      type: System.TimeSpan
      description: "A visszaadandó hangadatok kiindulási pontja."
    - id: duration
      type: System.TimeSpan
      description: "A visszaadandó szegmens hosszát."
    return:
      type: System.Speech.Recognition.RecognizedAudio
      description: "Adja vissza egy alkalmazásra vonatkozó a felismert hang által definiált <code> audioPosition </code> és <code> duration </code>."
  overload: System.Speech.Recognition.RecognizedAudio.GetRange*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "<code>audioPosition</code>és <code>duration</code> adja meg a jelenlegi szegmens tartományán kívül eső hang szegmense."
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "A jelenlegi felismert hang nem tartalmaz adatokat."
  platform:
  - net462
- uid: System.Speech.Recognition.RecognizedAudio.StartTime
  id: StartTime
  parent: System.Speech.Recognition.RecognizedAudio
  langs:
  - csharp
  name: StartTime
  nameWithType: RecognizedAudio.StartTime
  fullName: System.Speech.Recognition.RecognizedAudio.StartTime
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "A rendszer pontos ideje lekérdezi a felismerési művelet elején."
  remarks: "A StartTime tulajdonság beolvasása a rendszeridő megkezdése a felismerési, amelyek hasznosak lehetnek a számításokat késés és a teljesítmény.       A <xref:System.Speech.Recognition.RecognizedAudio.AudioPosition%2A>tulajdonság lekérdezi a helyet, a bemeneti eszköz létrehozott hangadatfolyam.</xref:System.Speech.Recognition.RecognizedAudio.AudioPosition%2A>"
  example:
  - "The following example handles the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized?displayProperty=fullName> or <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized?displayProperty=fullName> event and outputs to the console information about the recognized audio that is associated with the recognition result.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  RecognitionResult result = e.Result;  \n  \n  Console.WriteLine(\"Grammar({0}): {1}\",  \n    result.Grammar.Name, result.Text);  \n  \n  if (e.Result.Audio != null)  \n  {  \n    RecognizedAudio audio = e.Result.Audio;  \n  \n    Console.WriteLine(\"   start time: {0}\", audio.StartTime);  \n    Console.WriteLine(\"   encoding format: {0}\", audio.Format.EncodingFormat);  \n    Console.WriteLine(\"   position: {0}, duration: {1}\",  \n      audio.AudioPosition, audio.Duration);  \n  }  \n  \n  // Add event handler code here.  \n}  \n```"
  syntax:
    content: public DateTime StartTime { get; }
    return:
      type: System.DateTime
      description: "A rendszeridő a felismerési művelet elején."
  overload: System.Speech.Recognition.RecognizedAudio.StartTime*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognizedAudio.WriteToAudioStream(System.IO.Stream)
  id: WriteToAudioStream(System.IO.Stream)
  parent: System.Speech.Recognition.RecognizedAudio
  langs:
  - csharp
  name: WriteToAudioStream(Stream)
  nameWithType: RecognizedAudio.WriteToAudioStream(Stream)
  fullName: System.Speech.Recognition.RecognizedAudio.WriteToAudioStream(Stream)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "A teljes hang adatfolyamba írja az adatokat."
  remarks: "Hang adatot ír `outputStream` bináris formában. Nincs fejléc-információ része.       A WriteToAudioStream metódus Wave formátumot használja, de nem tartalmazza a hanghullám fejléce. Adja meg a hanghullám fejléce, használja a <xref:System.Speech.Recognition.RecognizedAudio.WriteToWaveStream%2A>metódus.</xref:System.Speech.Recognition.RecognizedAudio.WriteToWaveStream%2A>"
  syntax:
    content: public void WriteToAudioStream (System.IO.Stream outputStream);
    parameters:
    - id: outputStream
      type: System.IO.Stream
      description: "Az adatfolyam, amely a rendszer a hangadatok fogadásához."
  overload: System.Speech.Recognition.RecognizedAudio.WriteToAudioStream*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognizedAudio.WriteToWaveStream(System.IO.Stream)
  id: WriteToWaveStream(System.IO.Stream)
  parent: System.Speech.Recognition.RecognizedAudio
  langs:
  - csharp
  name: WriteToWaveStream(Stream)
  nameWithType: RecognizedAudio.WriteToWaveStream(Stream)
  fullName: System.Speech.Recognition.RecognizedAudio.WriteToWaveStream(Stream)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Hang ír egy adatfolyam Wave formátumban."
  remarks: "Hang adatot ír `outputStream` Wave formátumban, amely tartalmaz egy erőforrás interchange formátum (RIFF) fejlécét.       A <xref:System.Speech.Recognition.RecognizedAudio.WriteToAudioStream%2A>módszer ugyanazt a bináris formátumot használja, de nem tartalmazza a hanghullám fejléce.</xref:System.Speech.Recognition.RecognizedAudio.WriteToAudioStream%2A>"
  example:
  - "The following example creates a speech recognition grammar for name input, adds a handler for the <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event, and loads the grammar into an in-process speech recognizer. Then it writes the audio information for the name portion of the input to an audio file. The audio file is used as input to a <xref:System.Speech.Synthesis.SpeechSynthesizer> object, which speaks a phrase that includes the recorded audio.  \n  \n```  \nprivate static void AddNameGrammar(SpeechRecognitionEngine recognizer)  \n{  \n  GrammarBuilder builder = new GrammarBuilder();  \n  builder.Append(\"My name is\");  \n  builder.AppendWildcard();  \n  \n  Grammar nameGrammar = new Grammar(builder);  \n  nameGrammar.Name = \"Name Grammar\";  \n  nameGrammar.SpeechRecognized +=  \n    new EventHandler<SpeechRecognizedEventArgs>(  \n      NameSpeechRecognized);  \n  \n  recognizer.LoadGrammar(nameGrammar);  \n}  \n  \n// Handle the SpeechRecognized event of the name grammar.  \nprivate static void NameSpeechRecognized(  \n  object sender, SpeechRecognizedEventArgs e)  \n{  \n  Console.WriteLine(\"Grammar ({0}) recognized speech: {1}\",  \n    e.Result.Grammar.Name, e.Result.Text);  \n  \n  try  \n  {  \n    // The name phrase starts after the first three words.  \n    if (e.Result.Words.Count < 4)  \n    {  \n  \n      // Add code to check for an alternate that contains the   \nwildcard.  \n      return;  \n    }  \n  \n    RecognizedAudio audio = e.Result.Audio;  \n    TimeSpan start = e.Result.Words[3].AudioPosition;  \n    TimeSpan duration = audio.Duration - start;  \n  \n    // Add code to verify and persist the audio.  \n    string path = @\"C:\\temp\\nameAudio.wav\";  \n    using (Stream outputStream = new FileStream(path, FileMode.Create))  \n    {  \n      RecognizedAudio nameAudio = audio.GetRange(start, duration);  \n      nameAudio.WriteToWaveStream(outputStream);  \n      outputStream.Close();  \n    }  \n  \n    Thread testThread =  \n      new Thread(new ParameterizedThreadStart(TestAudio));  \n    testThread.Start(path);  \n  }  \n  catch (Exception ex)  \n  {  \n    Console.WriteLine(\"Exception thrown while processing audio:\");  \n    Console.WriteLine(ex.ToString());  \n  }  \n}  \n  \n// Use the speech synthesizer to play back the .wav file  \n// that was created in the SpeechRecognized event handler.  \n  \nprivate static void TestAudio(object item)  \n{  \n  string path = item as string;  \n  if (path != null && File.Exists(path))  \n  {  \n    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  \n    PromptBuilder builder = new PromptBuilder();  \n    builder.AppendText(\"Hello\");  \n    builder.AppendAudio(path);  \n    synthesizer.Speak(builder);  \n  }  \n}  \n```"
  syntax:
    content: public void WriteToWaveStream (System.IO.Stream outputStream);
    parameters:
    - id: outputStream
      type: System.IO.Stream
      description: "Az adatfolyam, amely a rendszer a hangadatok fogadásához."
  overload: System.Speech.Recognition.RecognizedAudio.WriteToWaveStream*
  exceptions: []
  platform:
  - net462
references:
- uid: System.Object
  isExternal: false
  name: System.Object
- uid: System.ArgumentOutOfRangeException
  isExternal: true
  name: System.ArgumentOutOfRangeException
- uid: System.InvalidOperationException
  isExternal: true
  name: System.InvalidOperationException
- uid: System.Speech.Recognition.RecognizedAudio.AudioPosition
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: AudioPosition
  nameWithType: RecognizedAudio.AudioPosition
  fullName: System.Speech.Recognition.RecognizedAudio.AudioPosition
- uid: System.TimeSpan
  parent: System
  isExternal: true
  name: TimeSpan
  nameWithType: TimeSpan
  fullName: System.TimeSpan
- uid: System.Speech.Recognition.RecognizedAudio.Duration
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: Duration
  nameWithType: RecognizedAudio.Duration
  fullName: System.Speech.Recognition.RecognizedAudio.Duration
- uid: System.Speech.Recognition.RecognizedAudio.Format
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: Format
  nameWithType: RecognizedAudio.Format
  fullName: System.Speech.Recognition.RecognizedAudio.Format
- uid: System.Speech.AudioFormat.SpeechAudioFormatInfo
  parent: System.Speech.AudioFormat
  isExternal: false
  name: SpeechAudioFormatInfo
  nameWithType: SpeechAudioFormatInfo
  fullName: System.Speech.AudioFormat.SpeechAudioFormatInfo
- uid: System.Speech.Recognition.RecognizedAudio.GetRange(System.TimeSpan,System.TimeSpan)
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: GetRange(TimeSpan,TimeSpan)
  nameWithType: RecognizedAudio.GetRange(TimeSpan,TimeSpan)
  fullName: System.Speech.Recognition.RecognizedAudio.GetRange(TimeSpan,TimeSpan)
- uid: System.Speech.Recognition.RecognizedAudio
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedAudio
  nameWithType: RecognizedAudio
  fullName: System.Speech.Recognition.RecognizedAudio
- uid: System.Speech.Recognition.RecognizedAudio.StartTime
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: StartTime
  nameWithType: RecognizedAudio.StartTime
  fullName: System.Speech.Recognition.RecognizedAudio.StartTime
- uid: System.DateTime
  parent: System
  isExternal: true
  name: DateTime
  nameWithType: DateTime
  fullName: System.DateTime
- uid: System.Speech.Recognition.RecognizedAudio.WriteToAudioStream(System.IO.Stream)
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: WriteToAudioStream(Stream)
  nameWithType: RecognizedAudio.WriteToAudioStream(Stream)
  fullName: System.Speech.Recognition.RecognizedAudio.WriteToAudioStream(Stream)
- uid: System.IO.Stream
  parent: System.IO
  isExternal: true
  name: Stream
  nameWithType: Stream
  fullName: System.IO.Stream
- uid: System.Speech.Recognition.RecognizedAudio.WriteToWaveStream(System.IO.Stream)
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: WriteToWaveStream(Stream)
  nameWithType: RecognizedAudio.WriteToWaveStream(Stream)
  fullName: System.Speech.Recognition.RecognizedAudio.WriteToWaveStream(Stream)
- uid: System.Speech.Recognition.RecognizedAudio.AudioPosition*
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: AudioPosition
  nameWithType: RecognizedAudio.AudioPosition
- uid: System.Speech.Recognition.RecognizedAudio.Duration*
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: Duration
  nameWithType: RecognizedAudio.Duration
- uid: System.Speech.Recognition.RecognizedAudio.Format*
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: Format
  nameWithType: RecognizedAudio.Format
- uid: System.Speech.Recognition.RecognizedAudio.GetRange*
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: GetRange
  nameWithType: RecognizedAudio.GetRange
- uid: System.Speech.Recognition.RecognizedAudio.StartTime*
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: StartTime
  nameWithType: RecognizedAudio.StartTime
- uid: System.Speech.Recognition.RecognizedAudio.WriteToAudioStream*
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: WriteToAudioStream
  nameWithType: RecognizedAudio.WriteToAudioStream
- uid: System.Speech.Recognition.RecognizedAudio.WriteToWaveStream*
  parent: System.Speech.Recognition.RecognizedAudio
  isExternal: false
  name: WriteToWaveStream
  nameWithType: RecognizedAudio.WriteToWaveStream
